{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7157,
     "status": "ok",
     "timestamp": 1717572497501,
     "user": {
      "displayName": "Ali Wehbe",
      "userId": "05622343126361511658"
     },
     "user_tz": -180
    },
    "id": "N2HqPtso34Xe"
   },
   "outputs": [],
   "source": [
    "# Global packages\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, roc_auc_score, auc\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22715,
     "status": "ok",
     "timestamp": 1717572520206,
     "user": {
      "displayName": "Ali Wehbe",
      "userId": "05622343126361511658"
     },
     "user_tz": -180
    },
    "id": "K9lQ_Ok64SrN",
    "outputId": "d7293f91-085c-407b-b831-810dc337fdf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1pqJ4n5lQIDV_SsyWpi3EWSywmMgBQHc7"
    },
    "executionInfo": {
     "elapsed": 16256,
     "status": "ok",
     "timestamp": 1717572536460,
     "user": {
      "displayName": "Ali Wehbe",
      "userId": "05622343126361511658"
     },
     "user_tz": -180
    },
    "id": "P1nWd83B4Ugd",
    "outputId": "c9d69b5d-fe21-45ea-8c50-fba8bcdc0170"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.transforms as T\n",
    "# from albumentations import Compose, HorizontalFlip, VerticalFlip, Rotate, RandomBrightnessContrast, Normalize, Resize\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# torchvision augmentation pipeline\n",
    "def torchvision_augmentation():\n",
    "    return T.Compose([\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        T.RandomRotation(degrees=45),\n",
    "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Albumentations augmentation pipeline\n",
    "def albumentations_augmentation():\n",
    "    return A.Compose([\n",
    "        # HorizontalFlip(p=0.5),\n",
    "        # VerticalFlip(p=0.5),\n",
    "        # Rotate(limit=45, p=0.5),\n",
    "        # RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        # Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        # ToTensorV2()\n",
    "        A.HorizontalFlip(p=0.5),  # Flips the image horizontally with a 50% chance\n",
    "        A.VerticalFlip(p=0.5),    # Flips the image vertically with a 50% chance\n",
    "        A.RandomRotate90(p=0.5),  # Randomly rotates the image 90 degrees with a 50% chance\n",
    "        A.Rotate(limit=40, p=0.5),  # Randomly rotates between -40 to +40 degrees\n",
    "        A.Blur(blur_limit=3, p=0.5),  # Applies blur\n",
    "        A.OpticalDistortion(p=0.3),  # Applies optical distortion\n",
    "        A.GridDistortion(p=0.3),  # Applies grid distortion\n",
    "        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50, p=0.5),  # Randomly changes hue, saturation, value\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),  # Randomly changes brightness and contrast\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),  # Adds Gaussian noise\n",
    "        A.CLAHE(clip_limit=2, p=0.5),  # Applies CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "        A.ToGray(p=0.2),  # Converts to grayscale with 20% chance\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # Normalizes image\n",
    "        ToTensorV2()  # Converts the image to a PyTorch tensor\n",
    "    ])\n",
    "\n",
    "# Load an image with PIL for torchvision and convert to tensor\n",
    "def load_image_for_torchvision(path):\n",
    "    image = Image.open(path)\n",
    "    return torchvision_augmentation()(image)\n",
    "\n",
    "# Load an image with OpenCV for Albumentations and apply transformation\n",
    "def load_image_for_albumentations(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    augmented = albumentations_augmentation()(image=image)\n",
    "    return augmented['image']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_and_save_augmented_images(image_path):\n",
    "    # Load images\n",
    "    torch_img = load_image_for_torchvision(image_path)\n",
    "    alb_img = load_image_for_albumentations(image_path)\n",
    "\n",
    "    # Convert tensor to numpy array for plotting (Torchvision)\n",
    "    torch_img = torch_img.permute(1, 2, 0).numpy()\n",
    "    torch_img = np.clip(torch_img, 0, 1)  # Clipping after normalization to avoid display issues\n",
    "\n",
    "    # Convert tensor to numpy array for plotting (Albumentations)\n",
    "    alb_img = alb_img.permute(1, 2, 0).numpy()  # This change is necessary for correct plotting\n",
    "    alb_img = np.clip(alb_img, 0, 1)  # Normalize for proper visualization\n",
    "\n",
    "    # Plot images\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axs[0].imshow(torch_img)\n",
    "    axs[0].set_title('Torchvision Augmented Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(alb_img)\n",
    "    axs[1].set_title('Albumentations Augmented Image')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig('augmented_images.png')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with a sample image path\n",
    "image_paths = ['../Dataset_BUSI_with_GT/benign/benign (1).png',\n",
    "               '../Dataset_BUSI_with_GT/benign/benign (2).png',\n",
    "               '../Dataset_BUSI_with_GT/benign/benign (3).png',\n",
    "               '../Dataset_BUSI_with_GT/benign/benign (4).png',\n",
    "               '../Dataset_BUSI_with_GT/benign/benign (5).png']\n",
    "for path in image_paths:\n",
    "  plot_and_save_augmented_images(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YS5zWlIr4-T1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPKJ2Hnf7NdwZUsEu5t3AjT",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
